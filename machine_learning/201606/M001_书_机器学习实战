001 本书结构
    第一部分    分类
        第01章  机器学习基础
        第02章  k-进邻算法
        第03章  决策树
        第04章  基于概率论的分类方法：朴素贝叶斯
        第05章  Logistic回归
        第06章  支持向量机
        弟07章  利用AdaBoost元算法提高分类性能
    第二部分    利用回归预测数值型数据
        第08章  预测数值型数据:回归
        第09章  树回归
    第三部分    无监督学习
        第10章  利用K-均值聚类算法对未标注数据分组
        第11章  使用Apriori算法进行关联分析
        第12章  使用FP-growth算法来高效发现频繁项集
    第四部分    其他工具
        第13章  利用PCA来简化数据
        第14章  利用SVD简化数据
        第15章  大数据与MapReduce
002 什么是机器学习
    a,  机器学习就是把无序的数据转换成有用的信息。
    b,  机器学习的主要任务是分类
    c,  要使用某个机器学习算法进行分析
            首先需要做的是算法训练，即学习如何分类。通常为算法输入大
        量已分类数据作为算法的训练集训练集是用于训练机器学习算法的数
        据样本集合
    c,  为了测试机器学习的效果，通常使用两套独立的样本集：训练数据和
        测试数据。
    d,  机器学习的另一项任务是回归(前面提到的任务是；分类)回归主要用
        于预测数据，回归的例子---数据拟合曲线
    e,  分类和回归属于监督学习，这类算法必须知道预测什么，即目标变量
        的分类信息。
    f,  与监督学习相对应的是无监督学习，此时数据没有类别信息，也不会
        给定目标值。
            在无监督学习中，将数据集合分成由类似的对象组成的多个类的
        过程被称为聚类；将寻找描述数据统计值得过程称之为密度估计。此
        外，无监督学习还可以减少数据特征的维度，以便我们可以使用二维
        或三维图形更加直观地展示数据信息。
    g,  机器学习的主要任务以及解决相应问题的算法。
                监督学习的用途
        k-近邻算法                  线性回归
        朴素贝叶斯算法              局部加权线性回归
        支持向量机                  Ridge回归
        决策树                      lasso最小回归系数估计
                无监督学习的用途
        K-均值                      最大期望算法
        DBSCAN                      Parzen窗设计
003 如何选择合适的算法
    a,  考虑问题一、使用机器学习算法的目的，想要算法完成何种任务，比
        如是预测明天下雨的概率还是对投票者按照兴趣分组
    b,  考虑问题二、需要分析或收集的数据是什么
    c,  如果想要预测目标变量的值，则可以选择监督学习算法；否则可以选
        择无监督学习算法。确定选择监督学习算法之后，需要进一步确定目
        标变量类型，如果目标变量是离散型，如是/否、1/2/3、A/B/C或者
        红/黄/黑等，则可以选择分类器算法；如果目标变量是连续型的数值
        ，如0.00~100.00、-999~999或者+无穷大 -无穷大等，则需要选择回
        归算法。
    e,  如果不想预测目标变量的值，则可以选择无监督学习算法。进一步分
        析是否需要将数据划分为离散的组。如果这是唯一的需求，则使用聚
        类算法；还需要估计数据与每个分组的相似程度，则需要使用密度估
        计算法。
    f,  其次需要考虑的是数据问题。对实际数据了解越充分，越容易创建符
        合实际需求的应用程序。主要应该了解数据的以下特性：特征值是离
        散型变量还是连续型变量，特征值中是否存在缺失的值，何种原因造
        成缺失值，数据中是否存在异常值，某个特征发生的频率如何(是否罕
        见得如同大海捞针)，等等。充分了解上面提到的这些数据特性可以缩
        短选择机器学习算法的时间。
    g,  我们只能在一定程度上缩小算法的选择范围，一般不存在最好的算法
        或者可以给出最好结果的算法，同时还要尝试不同算法的执行效果。
        对于所选的每种算法，都可以使用其他的机器学习技术来改进其性能
        。在处理输入数据之后，两个算法的相对性能也可能会发生变化。
    h,  机器学习算法虽然各部相同，但是使用算法创建应用程序的步骤却基
        本类似。
004 开发机器学习应用程序的步骤
    1,  收集数据
        爬虫，RSS返回，设备发送过来的实测数据(风速、血糖等)
    2,  准备输入数据
        得到数据之后，还必须确保数据格式符合要求。
    3,  分析输入数据
        分析以前得到的数据。
    4,  训练算法
        将前两步得到的格式化数据输入到算法，从中抽取知识或信息。这里
        得到的知识需要存储为计算机可以处理的格式。
        如果使用无监督学习算法，由于不存在目标变量值，故而也不需要训
        练算法， 所有与算法相关的内容都集中在第5步
    5,  测试算法
        实际使用第4步机器学习得到的知识信息。为了评估算法，必须测试算
        法的工作效果。对于监督学习，必须一致用于评估算法的目标变量值
        ；对于无监督学习，也必须用其他的评测手段来检测算法的成功率。
        无论哪种清醒，如果不满意算法的输出结果，则可以回到第4步，改进
        并加以测试。问题常常会跟数据的收集和准备有关，这时必须回到第1
        步重新开始。
    6,  使用算法
        将机器学习算法转换为应用程序，执行实际任务，以检验上诉步骤是
        否可以在实际环境中正常工作。此时，如果碰到新的问题，同样需要
        重复执行上诉的步骤。
005 Python的特点
    1,  Python的语法清晰
    2,  易于操作纯文本文件
    3,  使用广泛，存在大量的开发文档
    4,  Python可调用C编译的代码
006 NumPy函数库基础
    1,  >>> from numpy import *
    2,  NumPy矩阵与数组的区别
        NumPy函数库中存在两种不同的数据类型(矩阵matrix和数组array),
        都可以用于处理行列表示的数字元素。虽然它们看起来相似，但是在
        这两个数据类型上执行相同的数学运算可能得到不同的结果，其中
        NumPy函数库中的matrix与MATLAB中matrices等价。
    3,  调用mat()函数可以将数组转化为矩阵，输入下述命令
        >>> randMat=mat(random.rand(4,4))
        由于使用随机函数产生举证，不同计算机上输出的值可能略有不同
        >>> randMat.I
        .I操作符实现了矩阵的逆运算
        >>> invRandMat = randMat.I
        接着执行举证惩罚
        >>> randMat*invRandMat
        结果应该是单位矩阵，实际矩阵中留下许多非常小的元素
007 k-近邻算法本章内容：
    1,  k-近邻分类算法
    2,  从文本文件中解析和导入数据
    3,  使用Matplotlib创建扩散图
    4,  归一化数值
008 k-近邻算法(kNN)概述
    1,  优点：精度高、对异常值不敏感、无数据输入假定
        缺点：计算复杂度高、空间复杂度高
        适用数据范围：数值型和标称型
    2,  k-近邻算法(kNN)的工作原理是： 存在一个数据集合，也称作训练样本
        集，并且样本集中每个数据都存在标签，即我们知道样本集合中每一数
        据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个
        特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征
        最相似数据最近邻的分类标签。
    3,  一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近
        邻算法中k个出处，通常k是不大于20的整数。最后，选择k个最相似数
        据中出现次数最多的分类，作为新数据的分类。
    4,  k-近邻算法的一般流程
        a,  收集数据：可以使用任何方法
        b,  准备数据：距离计算所需要的数值，最好是结构化的数据格式
        c,  分析数据：可以使用任何方法
        d,  训练算法：此步骤不使用于k-近邻算法
        e,  测试算法：计算错误率
        f,  使用算法：首先需要输入样本数据和结构化的输出结果，然后运行
                      k-近邻算法判定输入数据分别属于哪个类，最后应用对
                      计算出的分类执行后续的处理
    5,  准备：使用Python导入数据
        a,  创建名为kNN.py的Python模块
        b,  构造完整的k-近邻算法之前，需要准备一些基本的通用函数
            from numpy import *
            import operator
            def createDataset():
                group=array([[1.0,1.1],[1.0,1.0],[0.0,0.0],[0.0,0.1]])
                labels=['A','A','B','B']
                return group,labels
            上面的代码中，导入了两个模块；科学计算包NumPy和运算符模块
        c,  为了方便使用createDataSet()函数，它创建数据集和标签，然后
            依次执行以下步骤：保存kNN.py文件，改变当前路径到存储kNN.py
            文件的位置，打开Python开发环境。
        d,  Python交互式开发
            >>> import kNN
            上述命令导入kNN模块。 
            >>> group.label=kNN.createDataSet()

