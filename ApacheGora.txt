2010年9月22日，Gora进入到Apache孵化器
Apache中与Hadoop相关的项目，它们在百度中的检索数:
    Apache Spark:       3,100,000
    Apache HBase:       2,050,000
    Apache Hive:        1,970,000
    Apache Pig:         1,640,000
    Apache Cassandra:   1,100,000
    Apache Mahout:      577,000
    Apache Avro:        376,000
    Apache Ambari:      215,000
    Apache Tez:         183,000
    Apache Gora:        59,400
可以明显看到，Apache Gora的中文检索数最少。作为Apache中与Hadoop相关的一个框架，我们有必要对Apache Gora有一个技术上的学习。

Apache Gora Project 什么是Apache Gora Project
The Apache Gora open source framework provides an in-memory data model and persistence for big data. Gora supports persisting to column stores, key value stores, document stores and RDBMSs, and analyzing the data with extensive Apache Hadoop MapReduce support.
Apache Gora是一个开源大数据持久化框架并提供内存数据模型。Gora提供持久化到列存储(column stores)，键值存储(key value stores)，非表结构存储(document stores)和关系型数据库管理系统(RDBMSs)。Gora通过Hadoop MapReduce扩展来分析数据。
Why Gora? 为什么选择Gora
Although there are various excellent ORM frameworks for relational databases, data modeling in NoSQL data stores differ profoundly from their relational cousins. Moreover, data-model agnostic frameworks such as JDO are not sufficient for use cases, where one needs to use the full power of the data models in column stores. Gora fills this gap by giving the user an easy-to-use ORM framework with data store specific mappings and built in Apache Hadoop support.
尽管关系型数据库有一系列优秀的ORM框架，NoSQL数据仓库的数据建模与关系型数据库有很大不同。此外，如果想要充分利用列存储的数据模型，以JDO为代表的不依赖具体实现的数据模型是远远不够的。Gora通过提供易于使用的ORM框架和数据仓库具体化映射和自带的Apache Hadoop支持，填补了这个空缺。
The overall goal for Gora is to become the standard data representation and persistence framework for big data. The roadmap of Gora can be grouped as follows.
    Data Persistence : Persisting objects to Column stores such as HBase, Cassandra, Hypertable; key-value stores such as Voldermort, Redis, etc; SQL databases, such as MySQL, HSQLDB, flat files in local file system or Hadoop HDFS.
    Data Access : An easy to use Java-friendly common API for accessing the data regardless of its location.
    Indexing : Persisting objects to Lucene and Solr indexes, accessing/querying the data with Gora API.
    Analysis : Accesing the data and making analysis through adapters for Apache Pig, Apache Hive and Cascading
    MapReduce support : Out-of-the-box and extensive MapReduce (Apache Hadoop) support for data in the data store.
Gora的总体目标是成为大数据中数据呈现和持久化的标准。Gora的路线图以如下展示：
    数据持久化：持久化对象到列存储(HBase,Cassandra,Hypertable)，键值存储(Voldermort,Redis)，SQL数据库(MySQL)，HSQLDB(没有关系结构的文件，在本地文件系统或HDFS)
    数据存取：一个易于使用的通用API,Java友好，用于存取数据而不考虑数据的实际存储位置
    数据检索：持久化对象到Lucene和Solr检索中，使用Gora API来存取和检索数据
    数据分析：通过提供给Apache Pig,Apache Hive和Cascading的适配器，来存取数据和做数据分析
    MapReduce支持：成熟易用有外延的MapReduce给数据仓库中的数据提供支持。
Background
ORM stands for Object Relation Mapping. It is a technology which abstacts the persistency layer (mostly Relational Databases) so that plain domain level objects can be used, without the cumbersome effort to save/load the data to and from the database. Gora differs from current solutions in that:
    1, Gora is specially focussed at NoSQL data stores, but also has limited support for SQL databases.
    2, The main use case for Gora is to access/analyze big data using Hadoop.
    3, Gora uses Avro for bean definition, not byte code enhancement or annotations.
    4, Object-to-data store mappings are backend specific, so that full data model can be utilized.
    5, Gora is simple since it ignores complex SQL mappings.
    6, Gora will support persistence, indexing and anaysis of data, using Pig, Lucene, Hive, etc.
    For the latest information about Gora, please visit our website at:http://gora.apache.org 
ORM是对象关系映射的简称。ORM技术抽象出持久化层，可以减少对数据库存取的繁重过程。Gora和现有解决方案的区别在于：
    1,Gora专门聚焦在NoSQL数据仓库，同时对SQL数据库有有限的支持。
    2,Gora的主要使用场景：使用Hadoop存取和分析大数据
    3,Gora使用Avro作bean定义，而不是字节码或注释
    4,Object-to-data存储映射是后端具体化的，那样的话就能够实现full-data-model
    5,Gora忽略复杂的SQL映射，故Gora是简单的
    6,Gora将会支持使用Pig,Lucene,Hive等来支持持久化，检索和数据分析
    获取Gora的最新信息，访问http://gora.apache.org
What Platform(s) does Gora work on? Gora运行在哪些平台
Gora builds nightly on Ubuntu.
The software has been tested and verified to run on the following platforms:
    Mac OSX 10.9.3
    Linux Mint
    Ubuntu
Gora does publish .zip artifacts for Windows users, however there is no gurantee of platform compatibility.
Gora在Ubuntu平台上开发
Gora已经在如下平台测试和认证：
    Mac OSX 10.9.2
    Linux Mint
    Ubuntu
Gora已经发布zip发行版供Windows用户，然而并不确保架构的通用性
Which Languages/Technologies do I need to know to use Gora? 使用Gora需要哪些编程语言和技能
    Gora is written in Java.
    Configuration however requires a working knowledge of syntax for JSON and XML.
    You should be able to use the command line terminal.
    You should be able to use Apache Maven from the command line.
    You should be able to edit simple flat files using a text editor.
    Gora由Java语言编写
    进行配置需要对JSON和XML语法有了解
    需要能熟练使用Terminal
    需要能够在Terminal中使用Apache Maven
    需要有文本编辑能力


Gora Modules Gora模块
Gora source code is organized in a modular architecture. The gora-core module is the main module which contains the core of the code. All other modules depend on the gora-core module. Each datastore backend in Gora resides in it's own module. The documentation for the specific module can be found at the module's documentation directory.
Gora源代码以模块化架构组织。Gora核心模块是包含代码核心的主模块。所有其他的模块依赖于主模块。以Gora为后端的每一个数据仓库都座落在它自己的仓库中。在模块文档中可以找到每一个具体模块的文档。
It is wise so start with going over the documentation for the gora-core module and then the specific data store module(s) you want to use. The following modules are currently implemented in Gora.
    gora-compiler: A page dedicated to the GoraCompiler; a critical part of the Gora workflow;
    gora-compiler-cli: A page dedicated to the GoraCompiler Command Line Interface; a utility module for working with the Gora Compiler;
    gora-shims-hadoop: Base module enabling us to use Gora with multiple versions of Hadoop in a flexible manner;
    gora-shims-hadoop-1.x: Module enabling us to use Gora with Hadoop 1.X;
    gora-shims-hadoop-2.x: Module enabling us to use Gora with Hadoop 2.X;
实现自己的数据仓库之前，过一遍Gora核心文档是非常有必要的。下面是Gora目前已经实现的模块：
    gora-compiler:用于GoraCompiler的一章，是Gora工作流中至关重要的一部分
    gora-compiler-cli:用于GoraCompiler命令控制台接口的一章，是GoraCompiler中的公共模块。
    gora-shims-hadoop:能够以灵活的方式兼容多版本的Hadoop
    gora-shims-hadoop-1.x:兼容Hadoop1.X的模块
    gora-shims-hadoop-2.x:兼容Hadoop2.X的模块
    gora-shims-hadoop-distribution: Packaging container module enabling easier dependency management whilst working with Gora Shims;
    gora-core: Module containing core functionality, AvroStore and DataFileAvroStore stores, GoraSparkEngine;
    gora-accumulo: Module for Apache Accumulo backend and AccumuloStore implementation;
    camel-gora: An Apache Camel component that allows you to work with NoSQL databases using Gora;
    gora-cassandra: Module for Apache Cassandra backend and CassandraStore implementation;
    gora-dynamodb: Module for Amazon DynamoDB backend and DynamoDBStore implementation;
    gora-hbase: Module for Apache HBase backend and HBaseStore implementation;
    gora-metamodel: Module for Apache MetaModel backend and query functionality;
    gora-mongodb: Module for MongoDB backend and MongoStore implementation;
    gora-solr: Module for Apache Solr backend and SolrStore implementation;
    gora-tutorial: The Gora LogManager tutorial;
    gora-sources-dist: Packaging module used to build and distribute Gora sources during project releases;
    gora-shims-hadoop-distribution:打包容器模块，简化依赖管理，与Gora Shims协同工作。
    gora-core:包含主要功能的模块，包含AvroStore和DataFileAcroStore仓库，GoraSparkEngine
    gora-accumulo:Apache Accumulo后端模块，AcumuloStore实现模块。
    camel-gora:一个Apache Camel组件，通过Gora来运行NoSQL
    gora-cassandra:Apacha Cassandra后端模块和Cassandra实现模块。
    gora-dynamodb:Amazon DynamoDb后端模块和DamoDBStore实现模块。
    gora-hbase:Apache HBase后端模块和HBaseStore实现模块。
    gora-metamodel:Apache MetaModel后端实现和查询功能模块。
    gora-mongodb:MongoDB后端模块和MongoStore实现模块
    gora-solr:Apache Solr后端模块和SolrStore实现模块
    gora-tutorial:Gora LogManager监管
    gora-sources-dist:在项目发行阶段，用于打包模块和发布Gora源代码
Gora Testing Gora测试
Gora currently has two testing mechanisms * JUnit Tests: These are included for every module which provides a DataStore within Gora. * Integration Tests: A custom testing suite called GoraCI (Continuous Ingestion) which stress tests Gora functionality at scale.
Gora目前有两个测试机制:JUnit Tests(在有Gora的每一个数据仓库模块中，都有JUnit Tests)和Integration Tests(一个叫GoraCI的自定义测试组件，在一定规模上对Gora功能进行压力测试)
JUnit Tests:
Unit tests in Gora are implemented using the popular JUnit framework. Each module which implements the DataStore interface similarly implements a DataStoreTestBase API which test utilities for DataStores. The DataStoreTestBase class delegates actual test execution to DataStoreTestUtil.
Gora中的单元测试使用流行的JUnit框架实现。实现数据仓库接口的每一个模块，同样实现了用来测试数据仓库功能的DataStoreTestBase API。DataStoreTestBase类将实际测试执行委托给DataStoreTestUtil。
The tests begin in a fairly trivial fashion testing functionality like datastore schema creation schema deletion, etc and continue in this manner getting progressively more complex as we begin testing some more advanced features within the Gora API. In addition to the unit tests contained within this class, the best place to look for API functionality is at the examples directories under various Gora modules. Most modules contain a /src/examples/ directory under which some example classes can be found. Specifically, there are some classes that are used for tests under gora-core/src/examples/.
测试以细致琐碎的方式来开始进行测试，如数据仓库建表和删表的测试。通过Gora API以类似的方式，进一步来测试Gora的高级特性。查看API功能的最佳是Gora模块的实例中。大部分模块中包中/src/examples/目录，里面放着一些实例。
GoraCI Integration Testsing Suite GoraCI整合测试套件
Background
Since Gora 0.5, the GoraCI suite has been part of the mainstream Gora codebase.
Credit for GoraCI can be handed to Keith Turner (Gora PMC member) for his foresight in developing GoraCI which we have now extended from gora-accumulo to the entire suite of Gora modules.
自Gora 0.5起，GoraCI已经成为主流Gora编码的一部分
GoraCI的荣誉归功于Keith Turner，用于嘉奖他在开发GoraCI的远见，由此GoraCI已经从gora-accumulo扩展到真个Gora模块套件中。
Apache Accumulo has a test suite that verifies that data is not lost at scale. This test suite is called continuous ingest.
Essentially the test runs many ingest clients that continually create linked lists containing 25 million nodes. At some point the clients are stopped and a map reduce job is run to ensure no linked list has a hole. A hole indicates data was lost.
The nodes in the linked list are random. This causes each linked list to spread across the table. Therefore if one part of a table loses data, then it will be detected by references in another part of the table.
This project is a version of the test suite written using Apache Gora [1]. Goraci has been tested against Accumulo and HBase.
Apache Accumulo 有一个测试套件用于保证数据在大规模应用中不会丢失。这个测试套件被叫做持续获取。
本质上，
